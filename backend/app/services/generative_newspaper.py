"""
generative_newspaper - T·ª± ƒë·ªông t·∫°o b√†i b√°o t·ª´ trending keywords
"""
import random
import time
import requests
from typing import List, Dict
from pytrends.request import TrendReq
import google.generativeai as genai


class generative_newspaper:
    """Class t·ª± ƒë·ªông l·∫•y trending keywords v√† t·∫°o b√†i vi·∫øt"""
    
    def __init__(self, api_key: str, unsplash_api_key: str = None):
        """
        Kh·ªüi t·∫°o generative_newspaper
        
        Args:
            api_key: Google Gemini API key
            unsplash_api_key: Unsplash API key (optional)
        """
        # Kh·ªüi t·∫°o pytrends v·ªõi timeout cao
        self.pytrends = TrendReq(
            hl='vi-VN', 
            tz=420,
            timeout=(10, 30)  # connection timeout, read timeout
        )
        self.trending_keywords: List[str] = []
        
        # Kh·ªüi t·∫°o Gemini
        genai.configure(api_key=api_key)
        # S·ª≠ d·ª•ng model m·ªõi nh·∫•t: gemini-2.5-flash
        self.model = genai.GenerativeModel('models/gemini-2.5-flash')
        
        # Unsplash API key
        self.unsplash_api_key = unsplash_api_key
        
        print("‚úÖ Kh·ªüi t·∫°o generative_newspaper th√†nh c√¥ng")
    
    def get_trending_keywords(self) -> List[str]:
        """
        L·∫•y 20 t·ª´ kh√≥a hot trending v·ªÅ: Vi·ªát Nam, C√¥ng Ngh·ªá, Crypto, Du l·ªãch
        
        Returns:
            List 20 t·ª´ kh√≥a trending
        """
        # Fallback keywords n·∫øu API b·ªã rate limit
        fallback_keywords = [
            # Vi·ªát Nam
            "c√¥ng ngh·ªá AI", "b√≥ng ƒë√° vi·ªát nam", "AI trong h·ªçc ƒë∆∞·ªùng", "gi√° v√†ng vi·ªát nam", "ch·ª©ng kho√°n",
            # C√¥ng ngh·ªá
            "AI 2025", "chatgpt", "tr√≠ tu·ªá nh√¢n t·∫°o", "ƒëi·ªán tho·∫°i m·ªõi", "c√¥ng ngh·ªá blockchain", "AI Agent",
            # Crypto
            "bitcoin", "crypto 2025", "ethereum", "gi√° bitcoin", "ƒë·∫ßu t∆∞ crypto",
            # Du l·ªãch
            "tour du l·ªãch", "du l·ªãch vi·ªát nam", "khu du l·ªãch", "du l·ªãch h√®", "ƒëi·ªÉm du l·ªãch hot"
        ]
        
        topics = ["Vi·ªát Nam", "C√¥ng Ngh·ªá", "Crypto", "Du l·ªãch"]
        all_keywords = []
        
        print(f"\n{'='*80}")
        print("üîç B·∫ÆT ƒê·∫¶U L·∫§Y TRENDING KEYWORDS")
        print(f"{'='*80}")
        
        def _pytrends_call(name, *args, retries: int = 4, initial_delay: float = 2.0, **kwargs):
            """Helper to call pytrends methods with retry + exponential backoff.

            name: method name on self.pytrends (str)
            args/kwargs: forwarded to the method
            retries: number of attempts
            initial_delay: base delay in seconds
            """
            for attempt in range(1, retries + 1):
                try:
                    method = getattr(self.pytrends, name)
                    return method(*args, **kwargs)
                except Exception as e:
                    # If last attempt, re-raise so caller can fallback
                    if attempt == retries:
                        print(f"   ‚ùå pytrends.{name} failed after {retries} attempts: {e}")
                        raise
                    # Exponential backoff with jitter
                    delay = initial_delay * (2 ** (attempt - 1)) + random.random()
                    print(f"   ‚ö†Ô∏è pytrends.{name} failed (attempt {attempt}/{retries}): {e}")
                    print(f"      ‚Üí Retrying in {delay:.1f}s...")
                    time.sleep(delay)

        for topic in topics:
            try:
                print(f"\nüìä ƒêang t√¨m trending cho: {topic}")

                # Increase delay to reduce chance of 429 (randomize a bit)
                wait = random.uniform(3.0, 6.0)
                print(f"   ‚è≥ ƒê·ª£i {wait:.1f} gi√¢y ƒë·ªÉ tr√°nh rate limit...")
                time.sleep(wait)

                # Build payload with retries
                _pytrends_call('build_payload', [topic], timeframe='now 7-d', retries=4, initial_delay=2.0)

                # Get related queries with retries
                related = _pytrends_call('related_queries', retries=4, initial_delay=2.0)

                if topic in related:
                    top = related[topic].get('top')
                    if top is not None and not top.empty:
                        keywords = top['query'].tolist()[:5]
                        all_keywords.extend(keywords)
                        print(f"   ‚úÖ L·∫•y ƒë∆∞·ª£c {len(keywords)} keywords:")
                        for kw in keywords:
                            print(f"      ‚Ä¢ {kw}")

            except Exception:
                # Don't print the low-level stack here; helper already logged attempts
                print(f"   ‚ö†Ô∏è S·ª≠ d·ª•ng fallback keywords cho {topic}")
        
        # N·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c t·ª´ API, d√πng fallback NGAY
        if len(all_keywords) < 10:  # Gi·∫£m threshold xu·ªëng 10
            print(f"\n‚ö†Ô∏è API ch·∫≠m ho·∫∑c b·ªã rate limit (ch·ªâ c√≥ {len(all_keywords)} keywords)")
            print(f"   ‚Üí S·ª≠ d·ª•ng fallback keywords")
            all_keywords = fallback_keywords
        # N·∫øu kh√¥ng ƒë·ªß 20, l·∫•y th√™m t·ª´ trending searches Vietnam
        elif len(all_keywords) < 20:
            try:
                print(f"\nüìä L·∫•y th√™m t·ª´ Trending Searches Vietnam...")
                time.sleep(2)  # Gi·∫£m t·ª´ 3 xu·ªëng 2
                trending = self.pytrends.trending_searches(pn='vietnam')
                extra_keywords = trending[0].tolist()
                all_keywords.extend(extra_keywords)
                print(f"   ‚úÖ L·∫•y th√™m ƒë∆∞·ª£c {len(extra_keywords)} keywords")
            except Exception as e:
                print(f"   ‚ùå L·ªói: {e}")
        
        # Lo·∫°i b·ªè duplicate, l·∫•y 20 ƒë·∫ßu ti√™n
        self.trending_keywords = list(dict.fromkeys(all_keywords))[:20]
        
        print(f"\n{'='*80}")
        print(f"‚úÖ HO√ÄN TH√ÄNH - T·ªïng c·ªông: {len(self.trending_keywords)} unique keywords")
        print(f"{'='*80}")
        
        return self.trending_keywords
    
    def search_images_unsplash(self, keyword: str, count: int = 4) -> List[Dict]:
        """
        T√¨m ki·∫øm ·∫£nh t·ª´ Unsplash API
        
        Args:
            keyword: T·ª´ kh√≥a t√¨m ki·∫øm
            count: S·ªë l∆∞·ª£ng ·∫£nh c·∫ßn l·∫•y
        
        Returns:
            List c√°c dict ch·ª©a image_url v√† alt_description
        """
        if not self.unsplash_api_key:
            print("‚ö†Ô∏è Kh√¥ng c√≥ Unsplash API key, d√πng ·∫£nh placeholder")
            return [
                {
                    "url": f"https://via.placeholder.com/1200x800?text={keyword.replace(' ', '+')}+{i+1}",
                    "alt": f"Image about {keyword} {i+1}"
                }
                for i in range(count)
            ]
        
        try:
            print(f"üñºÔ∏è ƒêang t√¨m {count} ·∫£nh cho keyword: '{keyword}'")
            
            headers = {
                "Authorization": f"Client-ID {self.unsplash_api_key}"
            }
            
            params = {
                "query": keyword,
                "per_page": count,
                "orientation": "landscape",
                "order_by": "latest"  # Latest photos thay v√¨ relevant ƒë·ªÉ c√≥ ·∫£nh ƒëa d·∫°ng h∆°n
            }
            
            response = requests.get(
                "https://api.unsplash.com/search/photos",
                headers=headers,
                params=params,
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                images = []
                
                for photo in data.get('results', [])[:count]:
                    images.append({
                        "url": photo['urls']['regular'],  # 1080px width
                        "alt": photo.get('alt_description') or photo.get('description') or keyword
                    })
                
                print(f"‚úÖ L·∫•y ƒë∆∞·ª£c {len(images)} ·∫£nh t·ª´ Unsplash")
                return images
            else:
                print(f"‚ö†Ô∏è Unsplash API error: {response.status_code}, d√πng placeholder")
                return [
                    {
                        "url": f"https://via.placeholder.com/1200x800?text={keyword.replace(' ', '+')}+{i+1}",
                        "alt": f"Image about {keyword} {i+1}"
                    }
                    for i in range(count)
                ]
        
        except Exception as e:
            print(f"‚ùå L·ªói t√¨m ·∫£nh: {e}, d√πng placeholder")
            return [
                {
                    "url": f"https://via.placeholder.com/1200x800?text={keyword.replace(' ', '+')}+{i+1}",
                    "alt": f"Image about {keyword} {i+1}"
                }
                for i in range(count)
            ]

    
    def generate_article(self, keyword: str) -> dict:
        """
        T·∫°o b√†i vi·∫øt t·ª´ keyword s·ª≠ d·ª•ng Gemini AI (sync)
        
        Args:
            keyword: T·ª´ kh√≥a ƒë·ªÉ t·∫°o b√†i vi·∫øt
        
        Returns:
            Dict ch·ª©a: title, slug, excerpt, content, category, status, thumbnail, images
        """
        prompt = f"""Vi·∫øt m·ªôt b√†i vi·∫øt chi ti·∫øt v·ªÅ ch·ªß ƒë·ªÅ: "{keyword}"

Y√™u c·∫ßu format tr·∫£ v·ªÅ CH√çNH X√ÅC theo m·∫´u sau (b·∫Øt bu·ªôc):

TITLE: [Ti√™u ƒë·ªÅ h·∫•p d·∫´n 80-100 k√Ω t·ª±]
SLUG: [url-slug-khong-dau]
CATEGORY: [Ch·ªçn 1 trong: Technology, Business, Health, Travel, Entertainment, Sports, Science, Politics, Lifestyle, Education]
EXCERPT: [T√≥m t·∫Øt ng·∫Øn 150-200 t·ª´]
CONTENT:
[N·ªôi dung ch√≠nh ƒë·∫ßy ƒë·ªß 1000-1500 t·ª´, chia th√†nh 3-4 ph·∫ßn v·ªõi ti√™u ƒë·ªÅ ph·ª• r√µ r√†ng. 
M·ªói ph·∫ßn c√°ch nhau b·∫±ng 2 d√≤ng tr·ªëng ƒë·ªÉ d·ªÖ ch√®n ·∫£nh.]

L∆∞u √Ω:
- TITLE: Ti√™u ƒë·ªÅ h·∫•p d·∫´n, thu h√∫t ng∆∞·ªùi ƒë·ªçc
- SLUG: Vi·∫øt li·ªÅn kh√¥ng d·∫•u, c√°ch nhau b·∫±ng d·∫•u g·∫°ch ngang (v√≠ d·ª•: bitcoin-tang-gia-manh)
- CATEGORY: Ph√¢n lo·∫°i ch√≠nh x√°c theo n·ªôi dung b√†i vi·∫øt
- EXCERPT: T√≥m t·∫Øt ng·∫Øn g·ªçn n·ªôi dung b√†i vi·∫øt
- CONTENT: N·ªôi dung ƒë·∫ßy ƒë·ªß, chuy√™n nghi·ªáp, c√≥ c·∫•u tr√∫c r√µ r√†ng
- Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát
- Phong c√°ch: Chuy√™n nghi·ªáp, d·ªÖ hi·ªÉu

B·∫Øt ƒë·∫ßu vi·∫øt ngay b√¢y gi·ªù theo ƒê√öNG format tr√™n:"""

        print(f"ü§ñ ƒêang t·∫°o b√†i vi·∫øt cho: '{keyword}'", flush=True)
        
        config = genai.types.GenerationConfig(
            max_output_tokens=8000,
            temperature=0.7
        )
        
        response = self.model.generate_content(prompt, generation_config=config)
        raw_content = response.text
        
        # Parse response th√†nh structured data
        article_data = self._parse_article_response(raw_content, keyword)
        
        print(f"‚úÖ T·∫°o n·ªôi dung ho√†n th√†nh!", flush=True)
        
        # T√¨m ki·∫øm 4 ·∫£nh t·ª´ Unsplash
        images = self.search_images_unsplash(keyword, count=4)
        
        # 1 ·∫£nh l√†m thumbnail
        thumbnail = images[0] if images else {"url": "", "alt": keyword}
        
        # 3 ·∫£nh c√≤n l·∫°i ch√®n v√†o content
        content_with_images = self._insert_images_to_content(
            article_data['content'], 
            images[1:4] if len(images) >= 4 else images[1:]
        )
        
        print(f"‚úÖ X·ª≠ l√Ω ·∫£nh ho√†n th√†nh!", flush=True)
        
        return {
            "title": article_data['title'],
            "slug": article_data['slug'],
            "category": article_data['category'],
            "status": "draft",  # M·∫∑c ƒë·ªãnh l√† draft
            "excerpt": article_data['excerpt'],
            "content": content_with_images,
            "thumbnail": thumbnail['url'],
            "thumbnail_alt": thumbnail['alt']
        }
    
    def _parse_article_response(self, raw_text: str, keyword: str) -> dict:
        """
        Parse response t·ª´ AI th√†nh structured data
        
        Args:
            raw_text: Raw text t·ª´ AI
            keyword: Keyword g·ªëc (d√πng l√†m fallback)
        
        Returns:
            Dict ch·ª©a title, slug, category, excerpt, content
        """
        import re
        
        # T√¨m c√°c ph·∫ßn trong response
        title_match = re.search(r'TITLE:\s*(.+?)(?:\n|$)', raw_text, re.IGNORECASE)
        slug_match = re.search(r'SLUG:\s*(.+?)(?:\n|$)', raw_text, re.IGNORECASE)
        category_match = re.search(r'CATEGORY:\s*(.+?)(?:\n|$)', raw_text, re.IGNORECASE)
        excerpt_match = re.search(r'EXCERPT:\s*(.+?)(?=\nCONTENT:|\n\n)', raw_text, re.IGNORECASE | re.DOTALL)
        content_match = re.search(r'CONTENT:\s*(.+)', raw_text, re.IGNORECASE | re.DOTALL)
        
        # Extract ho·∫∑c d√πng fallback
        title = title_match.group(1).strip() if title_match else f"B√†i vi·∫øt v·ªÅ {keyword}"
        slug = slug_match.group(1).strip() if slug_match else keyword.lower().replace(' ', '-')
        category = category_match.group(1).strip() if category_match else "Technology"
        excerpt = excerpt_match.group(1).strip() if excerpt_match else raw_text[:200]
        content = content_match.group(1).strip() if content_match else raw_text
        
        return {
            "title": title,
            "slug": slug,
            "category": category,
            "excerpt": excerpt,
            "content": content
        }
    
    def _insert_images_to_content(self, content: str, images: List[Dict]) -> str:
        """
        Ch√®n ·∫£nh ng·∫´u nhi√™n v√†o gi·ªØa c√°c ƒëo·∫°n trong content
        
        Args:
            content: N·ªôi dung b√†i vi·∫øt
            images: List c√°c dict ch·ª©a url v√† alt c·ªßa ·∫£nh
        
        Returns:
            Content ƒë√£ ƒë∆∞·ª£c ch√®n ·∫£nh
        """
        if not images:
            return content
        
        # T√°ch content th√†nh c√°c ƒëo·∫°n (split b·∫±ng 2 d√≤ng tr·ªëng ho·∫∑c ti√™u ƒë·ªÅ)
        paragraphs = content.split('\n\n')
        
        # N·∫øu c√≥ √≠t h∆°n 3 ƒëo·∫°n, kh√¥ng ch√®n ·∫£nh
        if len(paragraphs) < 3:
            return content
        
        # Ch·ªçn v·ªã tr√≠ ng·∫´u nhi√™n ƒë·ªÉ ch√®n ·∫£nh (kh√¥ng ch√®n ·ªü ƒëo·∫°n ƒë·∫ßu v√† cu·ªëi)
        available_positions = list(range(1, len(paragraphs) - 1))
        
        # Ch·ªçn t·ªëi ƒëa 3 v·ªã tr√≠ ng·∫´u nhi√™n
        insert_positions = random.sample(
            available_positions, 
            min(len(images), len(available_positions), 3)
        )
        insert_positions.sort(reverse=True)  # Sort ng∆∞·ª£c ƒë·ªÉ ch√®n t·ª´ cu·ªëi
        
        # Ch√®n ·∫£nh v√†o c√°c v·ªã tr√≠ ƒë√£ ch·ªçn
        for idx, position in enumerate(insert_positions):
            if idx < len(images):
                image = images[idx]
                image_html = f'\n\n<img src="{image["url"]}" alt="{image["alt"]}" style="width:100%; max-width:800px; height:auto; margin:20px 0;">\n\n'
                paragraphs.insert(position + 1, image_html)
        
        return '\n\n'.join(paragraphs)
    
    def run(self):
        """
        Ch·∫°y quy tr√¨nh t·ª± ƒë·ªông:
        1. L·∫•y 20 trending keywords
        2. Random ch·ªçn 1 keyword  
        3. T·∫°o b√†i vi·∫øt
        4. Log k·∫øt qu·∫£
        """
        print(f"\n{'#'*80}")
        print("üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH T·ª∞ ƒê·ªòNG T·∫†O B√ÄI VI·∫æT")
        print(f"{'#'*80}")
        
        # B∆∞·ªõc 1: L·∫•y trending keywords
        print("\n[B∆Ø·ªöC 1] L·∫•y trending keywords...")
        keywords = self.get_trending_keywords()
        
        if not keywords:
            print("‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c keywords!")
            return None
        
        print(f"\nüìã Danh s√°ch {len(keywords)} trending keywords:")
        for i, kw in enumerate(keywords, 1):
            print(f"   {i:2d}. {kw}")
        
        # B∆∞·ªõc 2: Random ch·ªçn 1 keyword
        print(f"\n[B∆Ø·ªöC 2] Random ch·ªçn keyword...")
        selected = random.choice(keywords)
        print(f"üé≤ ƒê√£ ch·ªçn: '{selected}'")
        
        # B∆∞·ªõc 3: T·∫°o b√†i vi·∫øt v√† x·ª≠ l√Ω ·∫£nh
        print(f"\n[B∆Ø·ªöC 3] T·∫°o b√†i vi·∫øt v√† x·ª≠ l√Ω ·∫£nh...")
        print("‚è≥ ƒêang x·ª≠ l√Ω, vui l√≤ng ƒë·ª£i...\n", flush=True)
        
        article = self.generate_article(selected)
        
        # B∆∞·ªõc 4: Log k·∫øt qu·∫£ SAU KHI x·ª≠ l√Ω xong H·∫æT
        print(f"\n{'='*80}")
        print("üìù K·∫æT QU·∫¢ CU·ªêI C√ôNG")
        print(f"{'='*80}")
        print(f"üîë Keyword: {selected}")
        print(f"üì∞ Title: {article['title']}")
        print(f"üîó Slug: {article['slug']}")
        print(f"üìÇ Category: {article['category']}")
        print(f"üìä Status: {article['status']}")
        print(f"üñºÔ∏è Thumbnail: {article['thumbnail'][:80]}...")
        print(f"üìù Excerpt: {len(article['excerpt'])} k√Ω t·ª±")
        print(f"üìÑ Content: {len(article['content'])} k√Ω t·ª±")
        print(f"{'='*80}")
        print("‚úÖ HO√ÄN TH√ÄNH QUY TR√åNH")
        print(f"{'='*80}\n")
        
        return {
            "keyword": selected,
            "title": article['title'],
            "slug": article['slug'],
            "category": article['category'],
            "status": article['status'],
            "excerpt": article['excerpt'],
            "content": article['content'],
            "thumbnail": article['thumbnail'],
            "thumbnail_alt": article['thumbnail_alt'],
            "content_length": len(article['content']),
            "word_count": len(article['content'].split())
        }
    
    def generate_full_article(self, keyword: str) -> Dict:
        """
        T·∫°o b√†i vi·∫øt HO√ÄN CH·ªàNH t·ª´ 1 keyword cho scheduler
        
        Args:
            keyword: T·ª´ kh√≥a ƒë·ªÉ t·∫°o b√†i vi·∫øt
            
        Returns:
            Dict ch·ª©a t·∫•t c·∫£ fields c·∫ßn thi·∫øt cho MongoDB
        """
        print(f"üìù Generating article for keyword: {keyword}")
        
        # Sinh article c∆° b·∫£n
        article = self.generate_article(keyword)
        
        # Map category AI sang enum backend
        category_map = {
            "AI Models": "technology",
            "Tech Innovations": "technology", 
            "Blockchain": "technology",
            "Software": "technology",
            "Healthcare": "health",
            "Finance": "business",
            "Economy": "business",
            "Politics": "politics",
            "Sports": "sports",
            "Entertainment": "entertainment",
            "Science": "science",
            "World News": "world",
            "Local News": "local",
            "Technology": "technology",
            "C√¥ng ngh·ªá": "technology",
            "Kinh t·∫ø": "business",
            "Ch√≠nh tr·ªã": "politics",
            "Th·ªÉ thao": "sports",
            "Gi·∫£i tr√≠": "entertainment",
            "S·ª©c kh·ªèe": "health",
            "Khoa h·ªçc": "science"
        }
        
        api_category = category_map.get(article.get('category', 'Technology'), 'technology')
        
        return {
            "title": article['title'],
            "slug": article['slug'],
            "excerpt": article['excerpt'],
            "content": article['content'],  # ƒê√£ c√≥ 3 ·∫£nh
            "category": api_category,
            "status": "published",
            "thumbnail": article['thumbnail'],
            "tags": [keyword] + article.get('tags', [])
        }


# Main ƒë·ªÉ ch·∫°y script
if __name__ == "__main__":
    import os
    from dotenv import load_dotenv
    
    # Load environment variables
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    unsplash_key = os.getenv("UNSPLASH_ACCESS_KEY")
    
    if not api_key:
        print("‚ùå Thi·∫øu GEMINI_API_KEY trong .env file!")
        print("üí° Th√™m v√†o file .env: GEMINI_API_KEY=your_api_key_here")
        exit(1)
    
    print("üöÄ Starting generative_newspaper...")
    print(f"üìÅ Script: {__file__}")
    print(f"üìÅ Unsplash API: {'‚úÖ Configured' if unsplash_key else '‚ö†Ô∏è Not configured (will use placeholders)'}")
    print(f"{'-'*80}\n")
    
    # Kh·ªüi t·∫°o v√† ch·∫°y
    newspaper = generative_newspaper(api_key=api_key, unsplash_api_key=unsplash_key)
    result = newspaper.run()
    
    if result:
        print(f"\n{'#'*80}")
        print("‚úÖ SCRIPT CH·∫†Y TH√ÄNH C√îNG!")
        print(f"{'#'*80}")
        print(f"Keyword: {result['keyword']}")
        print(f"Title: {result['title']}")
        print(f"Slug: {result['slug']}")
        print(f"Category: {result['category']}")
        print(f"Status: {result['status']}")
        print(f"Excerpt length: {len(result['excerpt'])} chars")
        print(f"Content length: {result['content_length']} chars")
        print(f"Word count: ~{result['word_count']} words")
        print(f"{'#'*80}\n")
        
        # In JSON output
        import json
        print("\n" + "="*80)
        print("üìÑ JSON OUTPUT:")
        print("="*80)
        json_output = {
            "title": result['title'],
            "slug": result['slug'],
            "category": result['category'],
            "status": result['status'],
            "excerpt": result['excerpt'],
            "content": result['content'],
            "thumbnail": result['thumbnail'],
            "thumbnail_alt": result['thumbnail_alt']
        }
        print(json.dumps(json_output, ensure_ascii=False, indent=2))
        print("="*80)
